{"cells":[{"metadata":{"dc":{"key":"4"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 1. Volatility changes over time\n<p>What is financial risk? </p>\n<p>Financial risk has many faces, and we measure it in many ways, but for now, let's agree that it is a measure of the possible loss on an investment. In financial markets, where we measure prices frequently, volatility (which is analogous to <em>standard deviation</em>) is an obvious choice to measure risk. But in real markets, volatility changes with the market itself. </p>\n<p><img src=\"https://assets.datacamp.com/production/project_738/img/VolaClusteringAssetClasses.png\" alt></p>\n<p>In the picture above, we see the returns of four very different assets. All of them exhibit alternating regimes of low and high volatilities. The highest volatility is observed around the end of 2008 - the most severe period of the recent financial crisis.</p>\n<p>In this notebook, we will build a model to study the nature of volatility in the case of US government bond yields.</p>"},{"metadata":{"dc":{"key":"4"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Load the packages\nlibrary(xts)\nlibrary(readr)\n\n# Load the data\nyc_raw <- read_csv(\"datasets/FED-SVENY.csv\")\n\n# Convert the data into xts format\nyc_all <- as.xts(x = yc_raw[, -1], order.by = yc_raw$Date)\n\n# Show only the tail of the 1st, 5th, 10th, 20th and 30th columns\nyc_all_tail <- tail(yc_all[, c(1, 5, 10, 20, 30)])\nyc_all_tail","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"12"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 2. Plotting the evolution of bond yields\n<p>In the output table of the previous task, we see the yields for some maturities.</p>\n<p>These data include the whole yield curve. The yield of a bond is the price of the money lent. The higher the yield, the more money you receive on your investment. The yield curve has many maturities; in this case, it ranges from 1 year to 30 years. Different maturities have different yields, but yields of neighboring maturities are relatively close to each other and also move together.</p>\n<p>Let's visualize the yields over time. We will see that the long yields (e.g. SVENY30) tend to be more stable in the long term, while the short yields (e.g. SVENY01) vary a lot. These movements are related to the monetary policy of the FED and economic cycles.</p>"},{"metadata":{"dc":{"key":"12"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"library(viridis)\n\n# Define plot arguments\nyields  <- yc_all\nplot.type  <- \"single\"\nplot.palette <- viridis(30) \nasset.names  <- colnames(yc_all)\n \n# Plot the time series\nplot.zoo(x = yields, plot.type = plot.type, col = plot.palette) \n\n# Add the legend\nlegend(x = \"topleft\", legend = asset.names,\n       col = plot.palette, cex = 0.45, lwd = 3)\n","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"19"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 3. Make the difference\n<p>In the output of the previous task, we see the level of bond yields for some maturities, but to understand how volatility evolves we have to examine the changes in the time series. Currently, we have yield levels; we need to calculate the changes in the yield levels. This is called \"differentiation\" in time series analysis. Differentiation has the added benefit of making a time series independent of time.</p>"},{"metadata":{"dc":{"key":"19"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Differentiate the time series  \nycc_all <- diff.xts(yc_all)\n\n# Show the tail of the 1st, 5th, 10th, 20th and 30th columns\nycc_all_tail <- tail(ycc_all[, c(1, 5, 10, 20, 30)])\nycc_all_tail","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"26"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 4. The US yields are no exceptions, but maturity matters\n<p>Now that we have a time series of the changes in US government yields let's examine it visually.</p>\n<p>By taking a look at the time series from the previous plots, we see hints that the returns following each other have some unique properties:</p>\n<ul>\n<li>The direction (positive or negative) of a return is mostly independent of the previous day's return. In other words, you don't know if the next day's return will be positive or negative just by looking at the time series.</li>\n<li>The magnitude of the return is similar to the previous day's return. That means, if markets are calm today, we expect the same tomorrow. However, in a volatile market (crisis), you should expect a similarly turbulent tomorrow.</li>\n</ul>"},{"metadata":{"dc":{"key":"26"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Define the plot parameters\nyield.changes <- ycc_all\nplot.type <- \"multiple\" \n\n\n# Plot the differentiated time series\nplot.zoo(x = yield.changes, plot.type = plot.type, \n     ylim = c(-0.5, 0.5), cex.axis = 0.7, \n     ylab = 1:30, col = plot.palette)","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"33"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 5. Let's dive into some statistics\n<p>The statistical properties visualized earlier can be measured by analytical tools. The simplest method is to test for autocorrelation. Autocorrelation measures how a datapoint's past determines the future of a time series. </p>\n<ul>\n<li>If the autocorrelation is close to 1, the next day's value will be very close to today's value. </li>\n<li>If the autocorrelation is close to 0, the next day's value will be unaffected by today's value.</li>\n</ul>\n<p>Because we are interested in the recent evolution of bond yields, we will filter the time series for data from 2000 onward.</p>"},{"metadata":{"dc":{"key":"33"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Filter for changes in and after 2000\nycc <- ycc_all[\"2000/\", ] \n\n# Save the 1-year and 20-year maturity yield changes into separate variables\nx_1 <- ycc[, \"SVENY01\"]\nx_20 <- ycc[, \"SVENY20\"]\n\n# Plot the autocorrelations of the yield changes\npar(mfrow=c(2,2))\nacf_1 <- acf(x_1)\nacf_20 <- acf(x_20) \n\n# Plot the autocorrelations of the absolute changes of yields\nacf_abs_1 <- acf(abs(x_1))\nacf_abs_20 <- acf(abs(x_20))","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"40"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 6. GARCH in action\n<p>A Generalized AutoRegressive Conditional Heteroskedasticity (<a href=\"https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity\">GARCH</a>) model is the most well known econometric tool to handle changing volatility in financial time series data. It assumes a hidden volatility variable that has a long-run average it tries to return to while the short-run behavior is affected by the past returns.</p>\n<p>The most popular form of the GARCH model assumes that the volatility follows this process:\n</p><p></p>\n<math>\n    &sigma;<sup>2</sup><sub>t</sub> = &omega; + &alpha; ⋅ &epsilon;<sup>2</sup><sub>t-1</sub> + &beta; ⋅ &sigma;<sup>2</sup><sub>t-1</sub>\n</math>\n<p></p><p></p>\n<math>        \nwhere &sigma; is the current volatility, &sigma;<sub>t-1</sub> the last day's volatility and &epsilon;<sub>t-1</sub> is the last day's return. The estimated parameters are &omega;, &alpha;, and &beta;.\n</math>\n<p>For GARCH modeling we will use <a href=\"https://cran.r-project.org/web/packages/rugarch/index.html\"><code>rugarch</code></a> package developed by Alexios Ghalanos.</p>"},{"metadata":{"dc":{"key":"40"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"library(rugarch)\n\n# Specify the GARCH model with the skewed t-distribution\nspec <- ugarchspec(distribution.model = \"sstd\")\n\n# Fit the model\nfit_1 <- ugarchfit(x_1, spec = spec)\n\n# Save the volatilities and the rescaled residuals\nvol_1 <- sigma(fit_1) \nres_1 <- scale(residuals(fit_1, standardize = TRUE)) * sd(x_1) + mean(x_1)\n\n# Plot the yield changes with the estimated volatilities and residuals\nmerge_1 <- merge.xts(x_1, vol_1, res_1)\nplot.zoo(merge_1)","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"47"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 7. Fitting the 20-year maturity\n<p>Let's do the same for the 20-year maturity. As we can see in the plot from Task 6, the bond yields of various maturities show similar but slightly different characteristics. These different characteristics can be the result of multiple factors such as the monetary policy of the FED or the fact that the investors might be different.</p>\n<p>Are there differences between the 1-year maturity and 20-year maturity plots?</p>"},{"metadata":{"dc":{"key":"47"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Fit the model\nfit_20 <- ugarchfit(x_20, spec = spec) \n\n# Save the volatilities and the rescaled residuals\nvol_20 <- sigma(fit_20)\nres_20 <- scale(residuals(fit_20, standardize = TRUE)) * sd(x_20) + mean(x_20)\n\n# Plot the yield changes with the estimated volatilities and residuals\nmerge_20 <- merge.xts(x_20, vol_20, res_20)\nplot.zoo(merge_20)","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"54"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 8. What about the distributions? (Part 1)\n<p>From the plots in Task 6 and Task 7, we can see that the 1-year GARCH model shows a similar but more erratic behavior compared to the 20-year GARCH model. Not only does the 1-year model have greater volatility, but the volatility of its volatility is larger than the 20-year model. That brings us to two statistical facts of financial markets not mentioned yet. </p>\n<ul>\n<li>The unconditional (before GARCH) distribution of the yield differences has heavier tails than the normal distribution.</li>\n<li>The distribution of the yield differences adjusted by the GARCH model has lighter tails than the unconditional distribution, but they are still heavier than the normal distribution.</li>\n</ul>\n<p>Let's find out what the fitted GARCH model did with the distribution we examined.</p>"},{"metadata":{"dc":{"key":"54"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Calculate the kernel density for the 1-year maturity and residuals\ndensity_x_1 <- density(x_1)\ndensity_res_1 <- density(res_1)\n\n# Plot the density diagram for the 1-year maturity and residuals\nplot(density_x_1) \nlines(density_res_1, col = \"red\")\n\n# Add the normal distribution to the plot\nnorm_dist <- dnorm(seq(-0.4, 0.4, by = .01), mean = mean(x_1), sd = sd(x_1))\nlines(seq(-0.4, 0.4, by = .01), \n      norm_dist, \n      col = \"darkgreen\"\n     )\n\n# Add legend\nlegend <- c(\"Before GARCH\", \"After GARCH\", \"Normal distribution\")\nlegend(\"topleft\", legend = legend, \n       col = c(\"black\", \"red\", \"darkgreen\"), lty=c(1,1))","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"61"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 9. What about the distributions? (Part 2)\n<p>In the previous plot, we see that the two distributions from the GARCH models are different from the normal distribution of the data, but the tails, where the differences are the most profound, are hard to see. Using a Q-Q plot will help us focus in on the tails.</p>\n<p>You can read an excellent summary of Q-Q plots <a href=\"https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot\">here</a>.</p>"},{"metadata":{"dc":{"key":"61"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Define the data to plot: the 1-year maturity yield changes and residuals \ndata_orig <- x_1\ndata_res <- res_1\n\n# Define the benchmark distribution\ndistribution <- qnorm\n\n# Make the Q-Q plot of original data with the line of normal distribution\nqqnorm(data_orig, ylim = c(-0.5, 0.5))\nqqline(data_orig, distribution = distribution, col = \"darkgreen\")\n\n# Make the Q-Q plot of GARCH residuals with the line of normal distribution\npar(new=TRUE)\nqqnorm(data_res * 0.614256270265139, col = \"red\", ylim = c(-0.5, 0.5))\nqqline(data_res * 0.614256270265139, distribution = distribution, col = \"darkgreen\")\nlegend(\"topleft\", c(\"Before GARCH\", \"After GARCH\"), col = c(\"black\", \"red\"), pch=c(1,1))","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"68"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 10. A final quiz\n<p>In this project, we fitted a GARCH model to develop a better understanding of how bond volatility evolves and how it affects the probability distribution. In the final task, we will evaluate our model. Did the model succeed, or did it fail?</p>"},{"metadata":{"dc":{"key":"68"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Q1: Did GARCH revealed how volatility changed over time? # Yes or No?\n(Q1 <- \"Yes\") \n\n# Q2: Did GARCH bring the residuals closer to normal distribution? Yes or No?\n(Q2 <- \"Yes\") \n\n# Q3: Which time series of yield changes deviates more \n# from a normally distributed white noise process? Choose 1 or 20.\n(Q3 <- 1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.5.3"}},"nbformat":4,"nbformat_minor":2}